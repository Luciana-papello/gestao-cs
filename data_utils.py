import pandas as pd
import numpy as np
import requests
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Tuple
from config import Config
import re
import json
import os

# Cache simples em mem√≥ria (para produ√ß√£o, usar Redis)
_cache = {}
_cache_timestamps = {}

def get_from_cache(key: str, timeout: int = 300):
    """Recupera dados do cache se ainda v√°lidos"""
    if key in _cache and key in _cache_timestamps:
        if datetime.now() - _cache_timestamps[key] < timedelta(seconds=timeout):
            return _cache[key]
    return None

def set_cache(key: str, data):
    """Armazena dados no cache"""
    _cache[key] = data
    _cache_timestamps[key] = datetime.now()

def load_google_sheet_public(sheet_id: str, tab_name: str = None) -> pd.DataFrame:
    """Carrega planilha p√∫blica do Google Sheets com cache e corre√ß√£o de data."""
    cache_key = f"{sheet_id}_{tab_name}"
    cached_data = get_from_cache(cache_key, Config.CACHE_TIMEOUT)
    
    if cached_data is not None:
        # Retorna uma c√≥pia para evitar modifica√ß√µes no cache
        return cached_data.copy()
    
    try:
        if tab_name:
            url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={tab_name}"
        else:
            url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv"
        
        df = pd.read_csv(url)
        df.columns = df.columns.str.strip()
        
        if 'data_pedido_realizado' in df.columns:
            print("INFO: Convertendo a coluna 'data_pedido_realizado' para datetime...")
            # CORRE√á√ÉO: Removido 'dayfirst=True'. Pandas ir√° inferir o formato ISO (YYYY-MM-DD) corretamente.
            df['data_pedido_realizado'] = pd.to_datetime(df['data_pedido_realizado'], errors='coerce')
            
            validas = df['data_pedido_realizado'].notna().sum()
            total = len(df)
            print(f"INFO: Convers√£o de data conclu√≠da. {validas}/{total} datas v√°lidas ({(validas/total*100):.1f}%).")

        set_cache(cache_key, df)
        # Retorna uma c√≥pia para o uso
        return df.copy()
        
    except Exception as e:
        print(f"ERRO: Falha ao carregar a planilha '{tab_name}': {str(e)}")
        return pd.DataFrame()

def load_satisfaction_data() -> pd.DataFrame:
    """Carrega dados de pesquisa de satisfa√ß√£o com corre√ß√£o de data brasileira"""
    cache_key = "satisfaction_data"
    cached_data = get_from_cache(cache_key, Config.CACHE_TIMEOUT)
    
    if cached_data is not None:
        return cached_data
    
    try:
        url = f"https://docs.google.com/spreadsheets/d/{Config.PESQUISA_SHEET_ID}/gviz/tq?tqx=out:csv"
        df = pd.read_csv(url)
        df.columns = df.columns.str.strip()
        
        date_cols = [col for col in df.columns if any(x in col.lower() for x in ['carimbo', 'data', 'timestamp'])]
        
        for col in date_cols:
            df[col] = pd.to_datetime(df[col], format='%d/%m/%Y %H:%M:%S', errors='coerce')
            mask_null = df[col].isnull()
            if mask_null.any():
                df.loc[mask_null, col] = pd.to_datetime(df.loc[mask_null, col], format='%d/%m/%Y', errors='coerce')
        
        set_cache(cache_key, df)
        return df.copy()
        
    except Exception as e:
        print(f"Erro ao carregar dados de satisfa√ß√£o: {str(e)}")
        return pd.DataFrame()

def convert_text_score_to_number(text_score) -> float:
    """Converte respostas em texto para valores num√©ricos"""
    if pd.isna(text_score) or text_score == "":
        return np.nan
    
    text_score = str(text_score).lower().strip()
    
    # Mapeamento otimizado
    mappings = {
        'entre 0 e 1': 0.5, 'entre 1 e 2': 1.5, 'entre 2 e 3': 2.5,
        'entre 3 e 4': 3.5, 'entre 4 e 5': 4.5, 'entre 5 e 6': 5.5,
        'entre 6 e 7': 6.5, 'entre 7 e 8': 7.5, 'entre 8 e 9': 8.5,
        'entre 9 e 10': 9.5, 'entre 1 e 6': 3.5
    }
    
    for key, value in mappings.items():
        if key in text_score:
            return value
    
    # Fallback para extra√ß√£o de n√∫meros
    numbers = re.findall(r'\d+', text_score)
    if len(numbers) >= 2:
        return (float(numbers[0]) + float(numbers[1])) / 2
    elif len(numbers) == 1:
        return float(numbers[0])
    
    return np.nan

def categorize_nps_from_text(text_score) -> str:
    """Categoriza respostas em texto para NPS"""
    if pd.isna(text_score) or text_score == "" or str(text_score).lower().strip() == "":
        return "Sem resposta"
    
    text_score = str(text_score).lower().strip()
    
    # Detratores (0-6)
    detrator_patterns = [
        'entre 0 e 1', 'entre 1 e 2', 'entre 2 e 3', 
        'entre 3 e 4', 'entre 4 e 5', 'entre 5 e 6', 
        'entre 1 e 6', '0', '1', '2', '3', '4', '5', '6'
    ]
    
    # Neutros (7-8)
    neutro_patterns = ['entre 7 e 8', '7', '8']
    
    # Promotores (9-10)
    promotor_patterns = ['entre 9 e 10', '9', '10']
    
    # Verificar padr√µes
    if any(pattern in text_score for pattern in promotor_patterns):
        return "Promotor"
    elif any(pattern in text_score for pattern in neutro_patterns):
        return "Neutro"
    elif any(pattern in text_score for pattern in detrator_patterns):
        return "Detrator"
    
    # Tentar extrair n√∫mero se for formato num√©rico direto
    numbers = re.findall(r'\d+', text_score)
    if numbers:
        try:
            score = int(numbers[0])
            if score >= 9:
                return "Promotor"
            elif score >= 7:
                return "Neutro"
            elif score >= 0:
                return "Detrator"
        except ValueError:
            pass
    
    return "Indefinido"

def calculate_priority_score(row) -> float:
    try:
        priority_weights = {'Premium': 100, 'Gold': 80, 'Silver': 60, 'Bronze': 40}
        churn_weights = {
            'Dormant_Premium': 300, 'Dormant_Gold': 250, 'Dormant_Silver': 200,
            'Dormant_Bronze': 150, 'Dormant_Novo': 120, 'Inativo': 100, 'Ativo': 0
        }
        risk_weights = {
            'Novo_Alto': 80, 'Alto': 50, 'Novo_M√©dio': 40,
            'M√©dio': 30, 'Novo_Baixo': 20, 'Baixo': 10
        }
        nivel = row.get('nivel_cliente', 'Bronze')
        risco = row.get('risco_recencia', 'Baixo')
        churn = row.get('status_churn', 'Ativo')
        top20 = 1 if row.get('top_20_valor', 'N√£o') == 'Sim' else 0
        return float(priority_weights.get(nivel, 40) + risk_weights.get(risco, 10) + churn_weights.get(churn, 0) + top20 * 25)
    except:
        return 0


def calculate_satisfaction_metrics(df_satisfacao: pd.DataFrame, column_name: str, 
                                 is_nps: bool = False, data_inicio=None, data_fim=None) -> Dict:
    """Calcula m√©tricas de satisfa√ß√£o com compara√ß√£o temporal"""
    if df_satisfacao.empty:
        return {
            'value': 'N/A',
            'trend': 'Sem dados',
            'color_class': 'info',
            'details': {}
        }
    
    # Usar per√≠odo padr√£o se n√£o especificado
    if not data_inicio or not data_fim:
        data_fim = datetime.now()
        data_inicio = data_fim - timedelta(days=30)
    
    # Buscar coluna de data
    date_column = None
    for col in df_satisfacao.columns:
        if any(x in col.lower() for x in ['carimbo', 'data', 'timestamp', 'time']):
            date_column = col
            break
    
    if not date_column or column_name not in df_satisfacao.columns:
        return {
            'value': 'N/A',
            'trend': 'Coluna n√£o encontrada',
            'color_class': 'info',
            'details': {}
        }
    
    # Filtrar dados no per√≠odo
    df_valid = df_satisfacao.dropna(subset=[date_column])
    dados_periodo = df_valid[
        (df_valid[date_column] >= data_inicio) & 
        (df_valid[date_column] <= data_fim)
    ]
    
    respostas_periodo = dados_periodo[column_name].dropna()
    
    if len(respostas_periodo) == 0:
        return {
            'value': 'N/A',
            'trend': 'Sem dados no per√≠odo',
            'color_class': 'warning',
            'details': {}
        }
    
    # Per√≠odo de compara√ß√£o
    periodo_dias = (data_fim - data_inicio).days
    inicio_comparacao = data_inicio - timedelta(days=periodo_dias)
    fim_comparacao = data_inicio
    
    dados_comparacao = df_valid[
        (df_valid[date_column] >= inicio_comparacao) & 
        (df_valid[date_column] < fim_comparacao)
    ]
    respostas_comparacao = dados_comparacao[column_name].dropna()
    
    if is_nps:
        # C√°lculo NPS
        categorias_periodo = respostas_periodo.apply(categorize_nps_from_text)
        promotores = (categorias_periodo == 'Promotor').sum()
        neutros = (categorias_periodo == 'Neutro').sum()
        detratores = (categorias_periodo == 'Detrator').sum()
        total_validas = promotores + neutros + detratores
        
        if total_validas == 0:
            return {
                'value': 'N/A',
                'trend': 'Sem respostas v√°lidas',
                'color_class': 'warning',
                'details': {}
            }
            
        nps_valor = ((promotores - detratores) / total_validas * 100)
        
        # Compara√ß√£o com per√≠odo anterior
        if len(respostas_comparacao) > 0:
            categorias_comp = respostas_comparacao.apply(categorize_nps_from_text)
            promotores_comp = (categorias_comp == 'Promotor').sum()
            detratores_comp = (categorias_comp == 'Detrator').sum()
            neutros_comp = (categorias_comp == 'Neutro').sum()
            total_comp = promotores_comp + neutros_comp + detratores_comp
            
            if total_comp > 0:
                nps_comp = ((promotores_comp - detratores_comp) / total_comp * 100)
                diferenca = nps_valor - nps_comp
                
                if diferenca > 5:
                    trend = f"‚ÜóÔ∏è +{diferenca:.0f} pts vs anterior"
                    color_class = "success"
                elif diferenca < -5:
                    trend = f"‚ÜòÔ∏è {diferenca:.0f} pts vs anterior"
                    color_class = "danger"
                else:
                    trend = f"‚û°Ô∏è {diferenca:+.0f} pts vs anterior"
                    color_class = "success" if nps_valor >= 50 else "warning" if nps_valor >= 0 else "danger"
            else:
                trend = f"{total_validas} avalia√ß√µes"
                color_class = "success" if nps_valor >= 50 else "warning" if nps_valor >= 0 else "danger"
        else:
            trend = f"{total_validas} avalia√ß√µes"
            color_class = "success" if nps_valor >= 50 else "warning" if nps_valor >= 0 else "danger"
            
        return {
            'value': f"{nps_valor:.0f}",
            'trend': trend,
            'color_class': color_class,
            'details': {
                'promotores': int(promotores),
                'neutros': int(neutros),
                'detratores': int(detratores),
                'total_validas': int(total_validas),
                'nps_valor': float(nps_valor)
}
        }
    
    else:
        # Outras m√©tricas (Atendimento, Produto, Prazo)
        scores = respostas_periodo.apply(convert_text_score_to_number).dropna()
        
        if len(scores) == 0:
            return {
                'value': 'N/A',
                'trend': 'Erro na convers√£o',
                'color_class': 'warning',
                'details': {}
            }
            
        valor = scores.mean()
        
        if len(respostas_comparacao) > 0:
            scores_comp = respostas_comparacao.apply(convert_text_score_to_number).dropna()
            if len(scores_comp) > 0:
                valor_comp = scores_comp.mean()
                diferenca = valor - valor_comp
                
                if diferenca > 0.3:
                    trend = f"‚ÜóÔ∏è +{diferenca:.1f} vs anterior"
                    color_class = "success"
                elif diferenca < -0.3:
                    trend = f"‚ÜòÔ∏è {diferenca:.1f} vs anterior"
                    color_class = "danger"
                else:
                    trend = f"‚û°Ô∏è {diferenca:+.1f} vs anterior"
                    color_class = "success" if valor >= 8 else "warning" if valor >= 6 else "danger"
            else:
                trend = f"{len(respostas_periodo)} avalia√ß√µes"
                color_class = "success" if valor >= 8 else "warning" if valor >= 6 else "danger"
        else:
            trend = f"{len(respostas_periodo)} avalia√ß√µes"
            color_class = "success" if valor >= 8 else "warning" if valor >= 6 else "danger"
            
        return {
            'value': f"{valor:.1f}/10",
            'trend': trend,
            'color_class': color_class,
            'details': {
                'valor_medio': valor,
                'total_respostas': len(respostas_periodo)
            }
        }

def load_google_sheet_corrected(sheet_id: str, sheet_name: str) -> pd.DataFrame:
    """Carregamento corrigido do Google Sheets que funciona com datas ISO"""
    try:
        url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}"
        print(f"üìä Carregando aba '{sheet_name}' com m√©todo corrigido...")
        
        # Carregar dados
        df = pd.read_csv(url)
        print(f"‚úÖ {len(df)} registros carregados")
        
        # Se tem coluna de data, converter corretamente
        if 'data_pedido_realizado' in df.columns:
            print("üîÑ Convertendo datas com m√©todo corrigido...")
            
            # M√∫ltiplos m√©todos de convers√£o para garantir sucesso
            df['data_original'] = df['data_pedido_realizado'].copy()
            
            # M√©todo 1: ISO format direto
            df['data_convertida'] = pd.to_datetime(df['data_pedido_realizado'], errors='coerce')
            
            # M√©todo 2: Se falhou, tentar outros formatos
            mask_nat = df['data_convertida'].isna()
            if mask_nat.sum() > 0:
                print(f"‚ö†Ô∏è {mask_nat.sum()} datas falharam na convers√£o ISO, tentando outros formatos...")
                
                # Tentar formato DD/MM/YYYY
                df.loc[mask_nat, 'data_convertida'] = pd.to_datetime(
                    df.loc[mask_nat, 'data_pedido_realizado'], 
                    format='%d/%m/%Y', 
                    errors='coerce'
                )
                
                # Tentar formato brasileiro
                mask_nat2 = df['data_convertida'].isna()
                if mask_nat2.sum() > 0:
                    df.loc[mask_nat2, 'data_convertida'] = pd.to_datetime(
                        df.loc[mask_nat2, 'data_pedido_realizado'], 
                        dayfirst=True, 
                        errors='coerce'
                    )
            
            # Substituir coluna original pela convertida
            df['data_pedido_realizado'] = df['data_convertida']
            
            # Estat√≠sticas de convers√£o
            validas = df['data_pedido_realizado'].notna().sum()
            total = len(df)
            print(f"üìä Convers√£o de datas: {validas}/{total} ({validas/total*100:.1f}%) v√°lidas")
            
            # Limpar colunas auxiliares
            df = df.drop(['data_original', 'data_convertida'], axis=1, errors='ignore')
        
        return df
        
    except Exception as e:
        print(f"‚ùå Erro ao carregar planilha: {e}")
        return pd.DataFrame()

def analyze_client_recurrence_corrected(df_pedidos: pd.DataFrame, data_inicio=None, data_fim=None) -> Dict:
    """
    Vers√£o corrigida e simplificada que analisa a recorr√™ncia de clientes.
    Funciona com datas corretamente carregadas.
    """
    if df_pedidos.empty:
        return {}
    
    try:
        print("üîç AN√ÅLISE DE RECORR√äNCIA - INICIANDO...")
        
        required_cols = ['data_pedido_realizado', 'status_pedido', 'cliente_unico_id', 'valor_do_pedido']
        if not all(col in df_pedidos.columns for col in required_cols):
            print(f"‚ùå Colunas necess√°rias n√£o encontradas. Requeridas: {required_cols}")
            return {}
        
        # Trabalhar com c√≥pia e garantir que a coluna de data √© do tipo datetime
        df_work = df_pedidos.copy()
        df_work['data_pedido_realizado'] = pd.to_datetime(df_work['data_pedido_realizado'], errors='coerce')
        
        # Remover quaisquer linhas onde a data n√£o p√¥de ser convertida
        df_valid_dates = df_work.dropna(subset=['data_pedido_realizado'])
        print(f"üìä Total de pedidos com datas v√°lidas: {len(df_valid_dates)} de {len(df_pedidos)}")

        # Aplicar filtro de data se fornecido
        if data_inicio and data_fim:
            df_periodo = df_valid_dates[
                (df_valid_dates['data_pedido_realizado'] >= pd.to_datetime(data_inicio)) &
                (df_valid_dates['data_pedido_realizado'] <= pd.to_datetime(data_fim))
            ]
        else:
            # Se n√£o houver per√≠odo, analisa todos os dados com datas v√°lidas
            df_periodo = df_valid_dates
        
        print(f"üìä Pedidos no per√≠odo selecionado: {len(df_periodo)}")
        if df_periodo.empty:
            return {
                'pedidos_primeira': 0, 'pedidos_recompra': 0, 'taxa_conversao': 0.0,
                'ticket_primeira': 0.0, 'ticket_recompra': 0.0, 'total_pedidos': 0, 'clientes_unicos': 0
            }

        # Limpar status e valor do pedido
        df_periodo['status_clean'] = df_periodo['status_pedido'].astype(str).str.strip().str.lower()
        df_periodo['valor_numerico'] = pd.to_numeric(
            df_periodo['valor_do_pedido'].astype(str).str.replace(',', '.').str.replace(r'[^\d.]', '', regex=True),
            errors='coerce'
        ).fillna(0)
        
        # Contar por status (usando a l√≥gica robusta de `cs.py`)
        primeiro_count = len(df_periodo[df_periodo['status_clean'] == 'primeiro'])
        recompra_count = len(df_periodo[df_periodo['status_clean'] == 'recompra'])
        
        # Calcular taxa de convers√£o
        taxa_conversao = 0.0
        df_primeiro = df_periodo[df_periodo['status_clean'] == 'primeiro']
        if not df_primeiro.empty:
            df_recompra = df_periodo[df_periodo['status_clean'] == 'recompra']
            clientes_primeiro = set(df_primeiro['cliente_unico_id'])
            clientes_recompra = set(df_recompra['cliente_unico_id'])
            clientes_convertidos = len(clientes_primeiro.intersection(clientes_recompra))
            if len(clientes_primeiro) > 0:
                taxa_conversao = (clientes_convertidos / len(clientes_primeiro)) * 100

        # Calcular tickets m√©dios
        ticket_primeiro = df_primeiro['valor_numerico'].mean() if not df_primeiro.empty else 0.0
        ticket_recompra = df_periodo[df_periodo['status_clean'] == 'recompra']['valor_numerico'].mean() if recompra_count > 0 else 0.0
        
        result = {
            'pedidos_primeira': int(primeiro_count),
            'pedidos_recompra': int(recompra_count),
            'taxa_conversao': float(taxa_conversao),
            'ticket_primeira': float(ticket_primeiro),
            'ticket_recompra': float(ticket_recompra),
            'total_pedidos': len(df_periodo),
            'clientes_unicos': df_periodo['cliente_unico_id'].nunique()
        }
        
        print(f"‚úÖ RESULTADO: {primeiro_count} primeira, {recompra_count} recompra, {taxa_conversao:.1f}% convers√£o")
        return result
        
    except Exception as e:
        print(f"‚ùå Erro na an√°lise de recorr√™ncia: {e}")
        import traceback
        traceback.print_exc()
        return {}

def get_latest_update_date(df_pedidos: pd.DataFrame) -> str:
    """Pega a data mais recente da planilha de pedidos"""
    if df_pedidos.empty:
        return "N/A"
    
    try:
        if 'data_pedido_realizado' not in df_pedidos.columns:
            return "N/A"
        
        df_temp = df_pedidos.copy()
        df_temp['data_pedido_realizado'] = pd.to_datetime(df_temp['data_pedido_realizado'], errors='coerce')
        
        dates_valid = df_temp['data_pedido_realizado'].dropna()
        
        if len(dates_valid) == 0:
            return "N/A"
        
        latest_date = dates_valid.max()
        
        if pd.isna(latest_date):
            return "N/A"
        
        return latest_date.strftime('%d/%m/%Y')
    
    except Exception as e:
        return "N/A"


def get_executive_summary_data() -> Dict:
    """Carrega todos os dados necess√°rios para a Vis√£o Executiva - VERS√ÉO COMPLETA"""
    try:
        print("üìä Iniciando carregamento dos dados executivos...")

        # Carregar dados das planilhas
        df_clientes = load_google_sheet_public(Config.CLASSIFICACAO_SHEET_ID, "classificacao_clientes3")
        df_pedidos = load_google_sheet_public(Config.CLASSIFICACAO_SHEET_ID, "pedidos_com_id2")
        df_satisfacao = load_satisfaction_data()

        print(f"‚úÖ Dados carregados: {len(df_clientes)} clientes, {len(df_pedidos)} pedidos, {len(df_satisfacao)} respostas de satisfa√ß√£o")

        if df_clientes.empty:
            print("‚ùå Planilha de clientes vazia")
            return {'error': 'N√£o foi poss√≠vel carregar dados dos clientes'}

        # Processar dados dos clientes
        df_clientes = df_clientes.copy()
        df_clientes['priority_score'] = df_clientes.apply(calculate_priority_score, axis=1)

        # Converter receita para num√©rico (essencial para c√°lculos)
        df_clientes['receita_num'] = pd.to_numeric(
            df_clientes['receita'].str.replace(',', '.'),
            errors='coerce'
        ).fillna(0)

        print(f"‚úÖ Dados processados: receita total R$ {df_clientes['receita_num'].sum():.0f}")

        # KPIs principais
        total_clientes = len(df_clientes)
        clientes_ativos = len(df_clientes[df_clientes['status_churn'] == 'Ativo'])
        clientes_criticos = len(df_clientes[df_clientes['priority_score'] >= 200])
        receita_total = df_clientes['receita_num'].sum()

        print(f"‚úÖ KPIs calculados: {total_clientes} clientes, {clientes_ativos} ativos, {clientes_criticos} cr√≠ticos")

        # An√°lise de recorr√™ncia (√∫ltimos 6 meses por padr√£o)
        data_fim_rec = datetime.now()
        data_inicio_rec = data_fim_rec - timedelta(days=180)
        recurrence_data = analyze_client_recurrence_corrected(df_pedidos, data_inicio_rec, data_fim_rec)

        # Buscar colunas de satisfa√ß√£o automaticamente
        satisfaction_columns = {
            'atendimento': None, 'produto': None, 'prazo': None, 'nps': None
        }

        if not df_satisfacao.empty:
            for col in df_satisfacao.columns:
                col_lower = col.lower()
                if 'atendimento' in col_lower and not satisfaction_columns['atendimento']:
                    satisfaction_columns['atendimento'] = col
                elif 'produto' in col_lower and not satisfaction_columns['produto']:
                    satisfaction_columns['produto'] = col
                elif 'prazo' in col_lower and not satisfaction_columns['prazo']:
                    satisfaction_columns['prazo'] = col
                elif any(x in col_lower for x in ['possibilidade', 'recomenda']) and not satisfaction_columns['nps']:
                    satisfaction_columns['nps'] = col

        # Calcular m√©tricas de satisfa√ß√£o (per√≠odo padr√£o de 30 dias)
        satisfaction_metrics = {}
        for metric_name, column_name in satisfaction_columns.items():
            if column_name:
                is_nps = (metric_name == 'nps')
                satisfaction_metrics[metric_name] = calculate_satisfaction_metrics(
                    df_satisfacao, column_name, is_nps
                )
            else:
                satisfaction_metrics[metric_name] = {
                    'value': 'N/A', 'trend': 'Coluna n√£o encontrada', 'color_class': 'info', 'details': {}
                }

        # Distribui√ß√µes para gr√°ficos
        nivel_distribution = df_clientes['nivel_cliente'].value_counts().to_dict()
        churn_distribution = df_clientes['status_churn'].value_counts().to_dict()
        risco_agrupado = df_clientes['risco_recencia'].map({
            'Alto': 'Alto Risco', 'Novo_Alto': 'Alto Risco',
            'M√©dio': 'M√©dio Risco', 'Novo_M√©dio': 'M√©dio Risco',
            'Baixo': 'Baixo Risco', 'Novo_Baixo': 'Baixo Risco'
        }).fillna('Sem Classifica√ß√£o').value_counts().to_dict()

        # Clientes Premium em risco para an√°lise cr√≠tica
        premium_em_risco = df_clientes[
            (df_clientes['nivel_cliente'].isin(['Premium', 'Gold'])) &
            (df_clientes['risco_recencia'].isin(['Alto', 'Novo_Alto', 'M√©dio', 'Novo_M√©dio']))
        ]

        print("‚úÖ Dados executivos processados com sucesso")

        # Estrutura de retorno completa para a API
        return {
            'kpis': {
                'total_clientes': total_clientes,
                'clientes_ativos': clientes_ativos,
                'taxa_retencao': (clientes_ativos / total_clientes * 100) if total_clientes > 0 else 0,
                'clientes_criticos': clientes_criticos,
                'taxa_criticos': (clientes_criticos / total_clientes * 100) if total_clientes > 0 else 0,
                'receita_total': receita_total
            },
            'recurrence': recurrence_data,
            'charts_data': {
                'pie_recurrence': recurrence_data.get('distribuicao_periodo', {}),
                'bar_tickets': {
                    'Primeira Compra': recurrence_data.get('ticket_primeira', 0),
                    'Recompra': recurrence_data.get('ticket_recompra', 0)
                }
            },
            'satisfaction': satisfaction_metrics,
            'distributions': {
                'nivel': nivel_distribution,
                'churn': churn_distribution,
                'risco': risco_agrupado
            },
            'critical_analysis': {
                'premium_em_risco': len(premium_em_risco),
                'total_premium': len(df_clientes[df_clientes['nivel_cliente'].isin(['Premium', 'Gold'])]),
                'receita_em_risco': premium_em_risco['receita_num'].sum() if len(premium_em_risco) > 0 else 0
            },
            'latest_update': get_latest_update_date(df_pedidos)
        }

    except Exception as e:
        print(f"‚ùå Erro ao carregar dados executivos: {str(e)}")
        import traceback
        traceback.print_exc()
        return {'error': f'Erro ao processar dados: {str(e)}'}
        


def clear_cache():
    """Limpa o cache interno"""
    global _cache, _cache_timestamps
    _cache.clear()
    _cache_timestamps.clear()
    print("‚úÖ Cache limpo com sucesso")
    

def format_number(value, prefix="", suffix=""):
    """Formata n√∫meros para exibi√ß√£o"""
    if pd.isna(value) or value == 0:
        return f"{prefix}0{suffix}"
    
    if value >= 1000000:
        return f"{prefix}{value/1000000:.1f}M{suffix}"
    elif value >= 1000:
        return f"{prefix}{value/1000:.0f}K{suffix}"
    else:
        return f"{prefix}{value:,.0f}{suffix}"

def format_phone_number(phone):
    """Formata n√∫mero de telefone"""
    if pd.isna(phone) or phone == "":
        return "N/A"
    
    phone_str = str(phone)
    if phone_str.endswith('.0'):
        phone_str = phone_str[:-2]
    
    return phone_str


def convert_text_score_to_number(text_score):
    """Converte respostas em texto para n√∫meros"""
    if pd.isna(text_score) or text_score == "":
        return np.nan
    
    text_score = str(text_score).lower().strip()
    
    # Mapeamento de respostas textuais
    text_mappings = {
        'excelente': 10,
        '√≥timo': 9,
        'muito bom': 8,
        'bom': 7,
        'regular': 6,
        'ruim': 4,
        'p√©ssimo': 2,
        'muito ruim': 3,
        'satisfeito': 8,
        'muito satisfeito': 9,
        'insatisfeito': 4,
        'muito insatisfeito': 2
    }
    
    # Procurar por mapeamentos textuais
    for key, value in text_mappings.items():
        if key in text_score:
            return value
    
    # Procurar por n√∫meros na string
    numbers = re.findall(r'\d+', text_score)
    if numbers:
        try:
            return float(numbers[0])
        except ValueError:
            pass
    
    return np.nan

def categorize_nps_from_text(text_score):
    """Categoriza respostas de NPS em texto"""
    if pd.isna(text_score) or text_score == "":
        return "Sem resposta"
    
    text_score = str(text_score).lower().strip()
    
    # Padr√µes para promotores
    promoter_patterns = [
        'entre 9 e 10', '9-10', 'promotor', 
        'muito prov√°vel', 'certamente', 'definitivamente'
    ]
    
    # Padr√µes para neutros
    neutral_patterns = [
        'entre 7 e 8', '7-8', 'neutro',
        'talvez', 'possivelmente', 'pode ser'
    ]
    
    # Padr√µes para detratores
    detractor_patterns = [
        'entre 0 e 6', '0-6', 'detrator', 'entre 1 e 6',
        'improv√°vel', 'nunca', 'jamais', 'n√£o recomendo'
    ]
    
    # Classificar baseado nos padr√µes
    if any(pattern in text_score for pattern in promoter_patterns):
        return "Promotor"
    elif any(pattern in text_score for pattern in neutral_patterns):
        return "Neutro"
    elif any(pattern in text_score for pattern in detractor_patterns):
        return "Detrator"
    
    # Tentar extrair n√∫mero se for formato num√©rico direto
    numbers = re.findall(r'\d+', text_score)
    if numbers:
        try:
            score = int(numbers[0])
            if score >= 9:
                return "Promotor"
            elif score >= 7:
                return "Neutro"
            elif score >= 0:
                return "Detrator"
        except ValueError:
            pass
    
    return "Indefinido"

def load_actions_log():
    """Carrega log de a√ß√µes (para compatibilidade com o Streamlit)"""
    actions_file = "cs_actions_log.json"
    if os.path.exists(actions_file):
        try:
            with open(actions_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"Erro ao carregar actions log: {str(e)}")
            return []
    return []

def save_action_log(action_data):
    """Salva a√ß√£o no log"""
    actions_file = "cs_actions_log.json"
    actions = load_actions_log()
    action_data['timestamp'] = datetime.now().isoformat()
    actions.append(action_data)
    
    try:
        with open(actions_file, 'w', encoding='utf-8') as f:
            json.dump(actions, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ A√ß√£o salva: {action_data.get('action_type', 'N/A')}")
    except Exception as e:
        print(f"‚ùå Erro ao salvar a√ß√£o: {str(e)}")


# === ADICIONAR esta fun√ß√£o no data_utils.py para DEBUG ===

def debug_status_pedido_values():
    """Debug espec√≠fico para investigar valores da coluna status_pedido"""
    try:
        from config import Config
        
        print("üîç DEBUG: Investigando valores de status_pedido...")
        
        # Carregar dados
        df_pedidos = load_google_sheet_public(Config.CLASSIFICACAO_SHEET_ID, "pedidos_com_id2")
        
        if df_pedidos.empty:
            print("‚ùå Planilha de pedidos vazia")
            return
        
        print(f"üìä Total de pedidos: {len(df_pedidos)}")
        print(f"üìã Colunas dispon√≠veis: {list(df_pedidos.columns)}")
        
        # Verificar se coluna existe
        if 'status_pedido' not in df_pedidos.columns:
            print("‚ùå PROBLEMA: Coluna 'status_pedido' n√£o encontrada!")
            print("üìã Colunas similares encontradas:")
            for col in df_pedidos.columns:
                if 'status' in col.lower() or 'pedido' in col.lower():
                    print(f"   - {col}")
            return
        
        # Investigar valores √∫nicos
        print("\nüîç VALORES √öNICOS da coluna 'status_pedido':")
        valores_unicos = df_pedidos['status_pedido'].value_counts()
        for valor, count in valores_unicos.items():
            print(f"   '{valor}' -> {count} ocorr√™ncias")
        
        # Investigar ap√≥s limpeza
        print("\nüîç VALORES AP√ìS LIMPEZA (lower + strip):")
        df_pedidos['status_clean'] = df_pedidos['status_pedido'].astype(str).str.strip().str.lower()
        valores_limpos = df_pedidos['status_clean'].value_counts()
        for valor, count in valores_limpos.items():
            print(f"   '{valor}' -> {count} ocorr√™ncias")
        
        # Testar varia√ß√µes de busca
        print("\nüîç TESTANDO VARIA√á√ïES DE BUSCA:")
        primeira_variations = ['primeiro', 'primeira', 'first', 'nova', 'novo']
        recompra_variations = ['recompra', 'repeat', 'recorrente', 'retorno']
        
        print("\nüìä PRIMEIRA COMPRA:")
        for variation in primeira_variations:
            count_isin = len(df_pedidos[df_pedidos['status_clean'].isin([variation])])
            count_contains = len(df_pedidos[df_pedidos['status_clean'].str.contains(variation, na=False)])
            print(f"   '{variation}' -> isin: {count_isin}, contains: {count_contains}")
        
        print("\nüìä RECOMPRA:")
        for variation in recompra_variations:
            count_isin = len(df_pedidos[df_pedidos['status_clean'].isin([variation])])
            count_contains = len(df_pedidos[df_pedidos['status_clean'].str.contains(variation, na=False)])
            print(f"   '{variation}' -> isin: {count_isin}, contains: {count_contains}")
        
        # Filtro por per√≠odo para comparar
        print(f"\nüîç FILTRANDO POR PER√çODO (√∫ltimos 180 dias)...")
        from datetime import datetime, timedelta
        
        df_pedidos['data_convertida'] = pd.to_datetime(df_pedidos['data_pedido_realizado'], errors='coerce')
        data_fim = datetime.now()
        data_inicio = data_fim - timedelta(days=180)
        
        df_periodo = df_pedidos[
            (df_pedidos['data_convertida'] >= data_inicio) &
            (df_pedidos['data_convertida'] <= data_fim)
        ]
        
        print(f"üìä Pedidos no per√≠odo: {len(df_periodo)}")
        
        if len(df_periodo) > 0:
            print("\nüìä STATUS NO PER√çODO:")
            status_periodo = df_periodo['status_clean'].value_counts()
            for valor, count in status_periodo.items():
                print(f"   '{valor}' -> {count} ocorr√™ncias")
        
        print("\n‚úÖ Debug conclu√≠do!")
        
    except Exception as e:
        print(f"‚ùå Erro no debug: {e}")
        import traceback
        traceback.print_exc()   

def debug_date_conversion():
    """Debug espec√≠fico para investigar problema na convers√£o de datas"""
    try:
        from config import Config
        from datetime import datetime, timedelta
        
        print("üîç DEBUG: Investigando convers√£o de datas...")
        
        # Carregar dados
        df_pedidos = load_google_sheet_public(Config.CLASSIFICACAO_SHEET_ID, "pedidos_com_id2")
        
        if df_pedidos.empty:
            print("‚ùå Planilha vazia")
            return
        
        print(f"üìä Total de pedidos carregados: {len(df_pedidos)}")
        
        # Verificar coluna de data
        print(f"\nüîç VALORES BRUTOS da coluna 'data_pedido_realizado':")
        print("Primeiras 5 datas:")
        for i in range(min(5, len(df_pedidos))):
            valor_bruto = df_pedidos.iloc[i]['data_pedido_realizado']
            print(f"   [{i}] '{valor_bruto}' (tipo: {type(valor_bruto)})")
        
        # Testar diferentes m√©todos de convers√£o
        print(f"\nüîç TESTANDO CONVERS√ïES DE DATA:")
        
        # M√©todo 1: Padr√£o (errors='coerce')
        print("1. Convers√£o padr√£o (errors='coerce'):")
        df_test1 = df_pedidos.copy()
        df_test1['data_conv_1'] = pd.to_datetime(df_test1['data_pedido_realizado'], errors='coerce')
        validas_1 = df_test1['data_conv_1'].notna().sum()
        print(f"   V√°lidas: {validas_1} de {len(df_pedidos)} ({validas_1/len(df_pedidos)*100:.1f}%)")
        
        # M√©todo 2: Formato espec√≠fico ISO
        print("2. Convers√£o com formato ISO (YYYY-MM-DD):")
        df_test2 = df_pedidos.copy()
        df_test2['data_conv_2'] = pd.to_datetime(df_test2['data_pedido_realizado'], format='%Y-%m-%d %H:%M:%S', errors='coerce')
        validas_2 = df_test2['data_conv_2'].notna().sum()
        print(f"   V√°lidas: {validas_2} de {len(df_pedidos)} ({validas_2/len(df_pedidos)*100:.1f}%)")
        
        # M√©todo 3: Sem especificar formato
        print("3. Convers√£o autom√°tica (sem format):")
        df_test3 = df_pedidos.copy()
        df_test3['data_conv_3'] = pd.to_datetime(df_test3['data_pedido_realizado'], errors='coerce')
        validas_3 = df_test3['data_conv_3'].notna().sum()
        print(f"   V√°lidas: {validas_3} de {len(df_pedidos)} ({validas_3/len(df_pedidos)*100:.1f}%)")
        
        # Usar o melhor m√©todo
        melhor_metodo = max([(validas_1, 1), (validas_2, 2), (validas_3, 3)])[1]
        print(f"\n‚úÖ MELHOR M√âTODO: {melhor_metodo}")
        
        if melhor_metodo == 1:
            df_work = df_test1
            df_work['data_convertida'] = df_work['data_conv_1']
        elif melhor_metodo == 2:
            df_work = df_test2
            df_work['data_convertida'] = df_work['data_conv_2']
        else:
            df_work = df_test3
            df_work['data_convertida'] = df_work['data_conv_3']
        
        # Remover nulos
        df_valid = df_work.dropna(subset=['data_convertida']).copy()
        print(f"üìä Pedidos com data v√°lida: {len(df_valid)}")
        
        # Investigar range de datas
        data_min = df_valid['data_convertida'].min()
        data_max = df_valid['data_convertida'].max()
        print(f"\nüìÖ RANGE DE DATAS na planilha:")
        print(f"   M√≠nima: {data_min}")
        print(f"   M√°xima: {data_max}")
        
        # Testar filtro de 180 dias com diferentes datas finais
        print(f"\nüîç TESTANDO FILTRO DE 180 DIAS:")
        
        # Teste A: Data fim = hoje
        data_fim_hoje = datetime.now()
        data_inicio_hoje = data_fim_hoje - timedelta(days=180)
        
        df_filtrado_hoje = df_valid[
            (df_valid['data_convertida'] >= data_inicio_hoje) &
            (df_valid['data_convertida'] <= data_fim_hoje)
        ]
        
        print(f"A. Fim=HOJE ({data_fim_hoje.strftime('%Y-%m-%d')}):")
        print(f"   In√≠cio: {data_inicio_hoje.strftime('%Y-%m-%d')}")
        print(f"   Registros: {len(df_filtrado_hoje)}")
        
        # Teste B: Data fim = data m√°xima da planilha
        data_fim_max = data_max
        data_inicio_max = data_fim_max - timedelta(days=180)
        
        df_filtrado_max = df_valid[
            (df_valid['data_convertida'] >= data_inicio_max) &
            (df_valid['data_convertida'] <= data_fim_max)
        ]
        
        print(f"B. Fim=MAX_PLANILHA ({data_fim_max.strftime('%Y-%m-%d')}):")
        print(f"   In√≠cio: {data_inicio_max.strftime('%Y-%m-%d')}")
        print(f"   Registros: {len(df_filtrado_max)}")
        
        # Teste C: √öltimos 180 dias dos dados dispon√≠veis
        print(f"C. AN√ÅLISE POR PER√çODO:")
        
        # Ver quantos registros por m√™s
        df_valid['ano_mes'] = df_valid['data_convertida'].dt.to_period('M')
        registros_por_mes = df_valid['ano_mes'].value_counts().sort_index()
        
        print("   Registros por m√™s:")
        for periodo, count in registros_por_mes.tail(10).items():
            print(f"     {periodo}: {count} registros")
        
        # An√°lise por status no per√≠odo que d√° mais registros
        periodo_correto = df_filtrado_max if len(df_filtrado_max) > len(df_filtrado_hoje) else df_filtrado_hoje
        
        print(f"\nüìä AN√ÅLISE DO MELHOR PER√çODO ({len(periodo_correto)} registros):")
        periodo_correto['status_clean'] = periodo_correto['status_pedido'].astype(str).str.strip().str.lower()
        
        primeiro_count = len(periodo_correto[periodo_correto['status_clean'] == 'primeiro'])
        recompra_count = len(periodo_correto[periodo_correto['status_clean'] == 'recompra'])
        
        print(f"   Primeiro: {primeiro_count}")
        print(f"   Recompra: {recompra_count}")
        print(f"   Total: {primeiro_count + recompra_count}")
        
        if primeiro_count + recompra_count > 3000:
            print("üéØ ESTE PARECE SER O PER√çODO CORRETO!")
        else:
            print("‚ö†Ô∏è Ainda n√£o encontrou o per√≠odo correto...")
        
        print("\n‚úÖ Debug de datas conclu√≠do!")
        
    except Exception as e:
        print(f"‚ùå Erro no debug de datas: {e}")
        import traceback
        traceback.print_exc()         